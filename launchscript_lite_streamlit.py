import streamlit as st
import requests
import re

st.set_page_config(page_title="LaunchScript Lite", layout="centered")

st.title("ðŸš€ LaunchScript Lite")
st.subheader("Turn your ideas into content with AI â€” no setup needed.")

# Using Falcon-7B Instruct for high-quality generation
API_URL = "https://api-inference.huggingface.co/models/tiiuae/falcon-7b-instruct"
headers = {"Authorization": f"Bearer {st.secrets['HUGGINGFACE_TOKEN']}"}

def clean_output(text):
    text = re.sub(r"(?i)as an ai language model.*?(\.|\n)", "", text)
    text = re.sub(r"(?i)(write|create|generate).*?:.*", "", text)
    text = re.sub(r"<.*?>", "", text)  # remove any HTML tags like <strong>
    text = text.replace('"', '').replace("'", '').strip()
    return text

def format_twitter_thread(raw_text):
    tweets = re.findall(r"(?:^|\n)(\d\.\s?.+?)(?=\n\d\.|\Z)", raw_text.strip(), re.DOTALL)
    tweets = [tweet.strip() for tweet in tweets if tweet.strip()]
    return "\n\n".join(tweets[:5])

def format_hooks(raw_text):
    hooks = re.findall(r"\d\.\s(.+?)(?=\n\d\.|\Z)", raw_text.strip(), re.DOTALL)
    cleaned = [h.strip(" .'\n") for h in hooks if len(h.strip()) > 10 and len(h.strip()) < 100]
    return "\n".join(cleaned[:3]) if cleaned else raw_text

def query_model(prompt):
    try:
        response = requests.post(API_URL, headers=headers, json={"inputs": prompt})
        if response.status_code != 200:
            return f"âš ï¸ Error: {response.status_code}"
        result = response.json()
        if isinstance(result, list) and "generated_text" in result[0]:
            return clean_output(result[0]["generated_text"])
        elif isinstance(result, dict) and "generated_text" in result:
            return clean_output(result["generated_text"])
        else:
            return "âš ï¸ The model responded but no text was returned. Try again."
    except Exception as e:
        return f"âš ï¸ Exception: {str(e)}"

def generate_all(prompt):
    outputs = {
        "ðŸ§µ Twitter Thread": query_model(
            f"Write a Twitter thread with 5 tweets that explains this topic: '{prompt}'. The first tweet should hook attention using the topic naturally. The rest should add value, build interest, and end with a takeaway or CTA. Number them 1-5 and limit to 280 characters each."
        ),
        "ðŸ’¼ LinkedIn Post": query_model(
            f"Write a personal and professional LinkedIn post for solo entrepreneurs. It should feel human, reflective, and helpful about this topic: {prompt}. Avoid saying 'as an AI model' and do not repeat the prompt."
        ),
        "ðŸŽ® YouTube Shorts Script": query_model(
            f"Write a fast-paced, conversational script for a YouTube Short (under 60 seconds) on the topic: {prompt}. Start with a hook, give 2-3 punchy value points, and end with a clear call to action. Do not mention AI."
        ),
        "ðŸŽ¯ Hook Ideas": query_model(
            f"Write 3 short, bold, curiosity-driven content hooks for social media about: {prompt}. Each should be under 80 characters. Format as: 1. Hook one 2. Hook two 3. Hook three. Do not explain or describe them."
        )
    }
    if "ðŸ§µ Twitter Thread" in outputs:
        outputs["ðŸ§µ Twitter Thread"] = format_twitter_thread(outputs["ðŸ§µ Twitter Thread"])
    if "ðŸŽ¯ Hook Ideas" in outputs:
        outputs["ðŸŽ¯ Hook Ideas"] = format_hooks(outputs["ðŸŽ¯ Hook Ideas"])
    return outputs

with st.form("content_form"):
    user_prompt = st.text_area("ðŸ’¡ What's your idea or topic?", height=100)
    submitted = st.form_submit_button("Generate Content")

if submitted and user_prompt:
    with st.spinner("Generating content..."):
        outputs = generate_all(user_prompt)
    for label, content in outputs.items():
        st.markdown(f"### {label}")
        st.write(content)
        st.markdown("---")
