import streamlit as st
import requests

st.set_page_config(page_title="LaunchScript Lite", layout="centered")

st.title("ğŸš€ LaunchScript Lite")
st.subheader("Turn your ideas into content with AI â€” no setup needed.")

# Swapped to Falcon-7B Instruct for high-quality responses
API_URL = "https://api-inference.huggingface.co/models/tiiuae/falcon-7b-instruct"
headers = {"Authorization": f"Bearer {st.secrets['HUGGINGFACE_TOKEN']}"}

def query_model(prompt):
    try:
        response = requests.post(API_URL, headers=headers, json={"inputs": prompt})
        if response.status_code != 200:
            return f"âš ï¸ Error: {response.status_code}"
        result = response.json()
        if isinstance(result, list) and "generated_text" in result[0]:
            return result[0]["generated_text"]
        elif isinstance(result, dict) and "generated_text" in result:
            return result["generated_text"]
        else:
            return "âš ï¸ The model responded but no text was returned. Try again."
    except Exception as e:
        return f"âš ï¸ Exception: {str(e)}"

def generate_all(prompt):
    return {
        "ğŸ§µ Twitter Thread": query_model(f"Write a 5-tweet thread for solo creators about: {prompt}"),
        "ğŸ’¼ LinkedIn Post": query_model(f"Write a short professional LinkedIn post about: {prompt}"),
        "ğŸ® YouTube Script": query_model(f"Write a 60-second YouTube script for: {prompt}"),
        "ğŸ¯ Hook Ideas": query_model(f"Write 3 catchy titles for a post about: {prompt}")
    }

with st.form("content_form"):
    user_prompt = st.text_area("ğŸ’¡ What's your idea or topic?", height=100)
    submitted = st.form_submit_button("Generate Content")

if submitted and user_prompt:
    with st.spinner("Generating content..."):
        outputs = generate_all(user_prompt)
    for label, content in outputs.items():
        st.markdown(f"### {label}")
        st.write(content)
        st.markdown("---")
